# Movie-Recommendation-Using-BERT
Movies Recommendation using BERT4Rec, a sequential recommendation model inspired by the BERT (Bidirectional Encoder Representations from Transformers) architecture

The current state-of-the-art models, while effective, often fall short in capturing the nuances of user interactions. These models typically use unidirectional sequential neural networks, which encode user interactions in a fixed order, limiting their ability to fully understand user preferences. To address these challenges, we introduce BERT4Rec, a sequential recommendation model inspired by the BERT (Bidirectional Encoder Representations from Transformers) architecture used in natural language processing (NLP). BERT4Rec leverages deep bidirectional self-attention mechanisms to model user behavior sequences, offering a more nuanced and comprehensive understanding of user interactions.
BERT4Rec is designed to overcome the limitations of traditional models by utilizing the Cloze objective for training. This involves predicting random masked items within user behavior sequences by jointly conditioning on their left and right context. By doing so, BERT4Rec can capture complex dependencies and provide more accurate and relevant recommendations. In this report, we apply BERT4Rec to movie recommendations using the MovieLens dataset, which includes interactions between 6,541 users, 3,423 movies, and 100k ratings. This dataset allows us to train and evaluate the model, demonstrating its potential to significantly enhance the accuracy of recommendations.
